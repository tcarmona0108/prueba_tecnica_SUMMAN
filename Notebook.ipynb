{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b45cb3b",
   "metadata": {},
   "source": [
    "# **Aplicación de modelo de segmentación de clientes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710573c",
   "metadata": {},
   "source": [
    "## **Preparación de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3aef6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importarr todas las librerías necesarias para el proyecto\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score\n",
    ")\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697dc2a",
   "metadata": {},
   "source": [
    "### *Sales*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347fd058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Row_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Order_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Order_Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Ship_Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Ship_Mode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Customer_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Country/Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "State/Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Postal_Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Discount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Profit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Productos.Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Productos.Sub-Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "unit_list_price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "profit_per_unit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "% utilidad",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Dias de envio",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Discount Band",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Discount Band Order",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7e9f4a8f-2a7b-42bc-b6cd-674f88018ff9",
       "rows": [
        [
         "0",
         "1",
         "US-2020-103800",
         "2020-01-03 00:00:00",
         "2020-01-07 00:00:00",
         "Standard Class",
         "DP-13000",
         "United States",
         "Houston",
         "Texas",
         "77095",
         "Central",
         "OFF-PA-10000174",
         "16.448",
         "2",
         "0.2",
         "5.5512",
         "Office Supplies",
         "Paper",
         "10.28",
         "2.7756",
         "0.27",
         "4",
         "1–20%",
         "1"
        ],
        [
         "1",
         "2",
         "US-2020-112326",
         "2020-01-04 00:00:00",
         "2020-01-08 00:00:00",
         "Standard Class",
         "PO-19195",
         "United States",
         "Naperville",
         "Illinois",
         "60540",
         "Central",
         "OFF-BI-10004094",
         "3.54",
         "2",
         "0.8",
         "-5.487",
         "Office Supplies",
         "Binders",
         "8.85",
         "-2.7435",
         "-0.31",
         "4",
         "71–80%",
         "7"
        ],
        [
         "2",
         "3",
         "US-2020-112326",
         "2020-01-04 00:00:00",
         "2020-01-08 00:00:00",
         "Standard Class",
         "PO-19195",
         "United States",
         "Naperville",
         "Illinois",
         "60540",
         "Central",
         "OFF-LA-10003223",
         "11.784",
         "3",
         "0.2",
         "4.2717",
         "Office Supplies",
         "Labels",
         "4.91",
         "1.4239",
         "0.29",
         "4",
         "1–20%",
         "1"
        ],
        [
         "3",
         "4",
         "US-2020-112326",
         "2020-01-04 00:00:00",
         "2020-01-08 00:00:00",
         "Standard Class",
         "PO-19195",
         "United States",
         "Naperville",
         "Illinois",
         "60540",
         "Central",
         "OFF-ST-10002743",
         "272.736",
         "3",
         "0.2",
         "-64.7748",
         "Office Supplies",
         "Storage",
         "113.64",
         "-21.5916",
         "-0.19",
         "4",
         "1–20%",
         "1"
        ],
        [
         "4",
         "5",
         "US-2020-141817",
         "2020-01-05 00:00:00",
         "2020-01-12 00:00:00",
         "Standard Class",
         "MB-18085",
         "United States",
         "Philadelphia",
         "Pennsylvania",
         "19143",
         "East",
         "OFF-AR-10003478",
         "19.536",
         "3",
         "0.2",
         "4.884",
         "Office Supplies",
         "Art",
         "8.14",
         "1.628",
         "0.2",
         "7",
         "1–20%",
         "1"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_ID</th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Ship_Date</th>\n",
       "      <th>Ship_Mode</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>City</th>\n",
       "      <th>State/Province</th>\n",
       "      <th>Postal_Code</th>\n",
       "      <th>...</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Productos.Category</th>\n",
       "      <th>Productos.Sub-Category</th>\n",
       "      <th>unit_list_price</th>\n",
       "      <th>profit_per_unit</th>\n",
       "      <th>% utilidad</th>\n",
       "      <th>Dias de envio</th>\n",
       "      <th>Discount Band</th>\n",
       "      <th>Discount Band Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>US-2020-103800</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>DP-13000</td>\n",
       "      <td>United States</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>77095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.5512</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Paper</td>\n",
       "      <td>10.28</td>\n",
       "      <td>2.7756</td>\n",
       "      <td>0.27</td>\n",
       "      <td>4</td>\n",
       "      <td>1–20%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>US-2020-112326</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>PO-19195</td>\n",
       "      <td>United States</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>60540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-5.4870</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Binders</td>\n",
       "      <td>8.85</td>\n",
       "      <td>-2.7435</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>4</td>\n",
       "      <td>71–80%</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US-2020-112326</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>PO-19195</td>\n",
       "      <td>United States</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>60540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.2717</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>4.91</td>\n",
       "      <td>1.4239</td>\n",
       "      <td>0.29</td>\n",
       "      <td>4</td>\n",
       "      <td>1–20%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2020-112326</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>PO-19195</td>\n",
       "      <td>United States</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>60540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-64.7748</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>113.64</td>\n",
       "      <td>-21.5916</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>4</td>\n",
       "      <td>1–20%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2020-141817</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>MB-18085</td>\n",
       "      <td>United States</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>19143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.8840</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Art</td>\n",
       "      <td>8.14</td>\n",
       "      <td>1.6280</td>\n",
       "      <td>0.20</td>\n",
       "      <td>7</td>\n",
       "      <td>1–20%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row_ID        Order_ID Order_Date  Ship_Date       Ship_Mode Customer_ID  \\\n",
       "0       1  US-2020-103800 2020-01-03 2020-01-07  Standard Class    DP-13000   \n",
       "1       2  US-2020-112326 2020-01-04 2020-01-08  Standard Class    PO-19195   \n",
       "2       3  US-2020-112326 2020-01-04 2020-01-08  Standard Class    PO-19195   \n",
       "3       4  US-2020-112326 2020-01-04 2020-01-08  Standard Class    PO-19195   \n",
       "4       5  US-2020-141817 2020-01-05 2020-01-12  Standard Class    MB-18085   \n",
       "\n",
       "  Country/Region          City State/Province Postal_Code  ... Discount  \\\n",
       "0  United States       Houston          Texas       77095  ...      0.2   \n",
       "1  United States    Naperville       Illinois       60540  ...      0.8   \n",
       "2  United States    Naperville       Illinois       60540  ...      0.2   \n",
       "3  United States    Naperville       Illinois       60540  ...      0.2   \n",
       "4  United States  Philadelphia   Pennsylvania       19143  ...      0.2   \n",
       "\n",
       "    Profit  Productos.Category  Productos.Sub-Category  unit_list_price  \\\n",
       "0   5.5512     Office Supplies                   Paper            10.28   \n",
       "1  -5.4870     Office Supplies                 Binders             8.85   \n",
       "2   4.2717     Office Supplies                  Labels             4.91   \n",
       "3 -64.7748     Office Supplies                 Storage           113.64   \n",
       "4   4.8840     Office Supplies                     Art             8.14   \n",
       "\n",
       "   profit_per_unit % utilidad Dias de envio  Discount Band  \\\n",
       "0           2.7756       0.27             4          1–20%   \n",
       "1          -2.7435      -0.31             4         71–80%   \n",
       "2           1.4239       0.29             4          1–20%   \n",
       "3         -21.5916      -0.19             4          1–20%   \n",
       "4           1.6280       0.20             7          1–20%   \n",
       "\n",
       "   Discount Band Order  \n",
       "0                    1  \n",
       "1                    7  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar archivo de \"Sales\"\n",
    "\n",
    "sales = pd.read_excel('Sales.xlsx')\n",
    "\n",
    "sales.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c11abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar columnas innecesarias\n",
    "\n",
    "sales = sales.drop(columns=['Discount Band Order', 'Discount Band', 'Dias de envio', 'profit_per_unit' ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "978ae563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11737 entries, 0 to 11736\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   Row_ID                  11737 non-null  int64         \n",
      " 1   Order_ID                11737 non-null  object        \n",
      " 2   Order_Date              11737 non-null  datetime64[ns]\n",
      " 3   Ship_Date               11737 non-null  datetime64[ns]\n",
      " 4   Ship_Mode               11737 non-null  object        \n",
      " 5   Customer_ID             11737 non-null  object        \n",
      " 6   Country/Region          11666 non-null  object        \n",
      " 7   City                    11737 non-null  object        \n",
      " 8   State/Province          11737 non-null  object        \n",
      " 9   Postal_Code             11737 non-null  object        \n",
      " 10  Region                  11737 non-null  object        \n",
      " 11  Product_ID              11737 non-null  object        \n",
      " 12  Sales                   11737 non-null  float64       \n",
      " 13  Quantity                11737 non-null  int64         \n",
      " 14  Discount                11737 non-null  float64       \n",
      " 15  Profit                  11737 non-null  float64       \n",
      " 16  Productos.Category      11737 non-null  object        \n",
      " 17  Productos.Sub-Category  11737 non-null  object        \n",
      " 18  unit_list_price         11737 non-null  float64       \n",
      " 19  % utilidad              11737 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(5), int64(2), object(11)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d164aa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Row_ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Order_Date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Ship_Date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Sales",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Quantity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Discount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Profit",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "unit_list_price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "% utilidad",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c92dce28-9f8e-496e-b5de-2ca99af333a9",
       "rows": [
        [
         "count",
         "11737.0",
         "11737",
         "11737",
         "11737.0",
         "11737.0",
         "11737.0",
         "11737.0",
         "11737.0",
         "11737.0"
        ],
        [
         "mean",
         "5125.5083070631335",
         "2022-05-03 18:51:33.601431040",
         "2022-05-07 12:18:13.158387712",
         "228.08588192894265",
         "3.7787339183777795",
         "0.1566550225781716",
         "29.074615472437593",
         "75.92176619716714",
         "0.18540354246928248"
        ],
        [
         "min",
         "1.0",
         "2020-01-03 00:00:00",
         "2020-01-07 00:00:00",
         "0.444",
         "1.0",
         "0.0",
         "-6599.978",
         "0.99",
         "-0.63"
        ],
        [
         "25%",
         "2573.0",
         "2021-05-23 00:00:00",
         "2021-05-27 00:00:00",
         "17.34",
         "2.0",
         "0.0",
         "1.7608",
         "6.48",
         "0.06"
        ],
        [
         "50%",
         "5143.0",
         "2022-07-03 00:00:00",
         "2022-07-04 00:00:00",
         "53.97",
         "3.0",
         "0.2",
         "8.694",
         "19.98",
         "0.26"
        ],
        [
         "75%",
         "7668.0",
         "2023-05-18 00:00:00",
         "2023-05-20 00:00:00",
         "207.35",
         "5.0",
         "0.2",
         "29.245",
         "73.95",
         "0.33"
        ],
        [
         "max",
         "10194.0",
         "2023-12-30 00:00:00",
         "2024-01-05 00:00:00",
         "22638.48",
         "14.0",
         "0.8",
         "8399.976",
         "7546.16",
         "0.5"
        ],
        [
         "std",
         "2941.568558405",
         null,
         null,
         "621.061888927641",
         "2.2135938229467467",
         "0.2068935681704687",
         "235.88112364412",
         "191.88270876648085",
         "0.232253501211812"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row_ID</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Ship_Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>unit_list_price</th>\n",
       "      <th>% utilidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11737.000000</td>\n",
       "      <td>11737</td>\n",
       "      <td>11737</td>\n",
       "      <td>11737.000000</td>\n",
       "      <td>11737.000000</td>\n",
       "      <td>11737.000000</td>\n",
       "      <td>11737.000000</td>\n",
       "      <td>11737.000000</td>\n",
       "      <td>11737.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5125.508307</td>\n",
       "      <td>2022-05-03 18:51:33.601431040</td>\n",
       "      <td>2022-05-07 12:18:13.158387712</td>\n",
       "      <td>228.085882</td>\n",
       "      <td>3.778734</td>\n",
       "      <td>0.156655</td>\n",
       "      <td>29.074615</td>\n",
       "      <td>75.921766</td>\n",
       "      <td>0.185404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>2020-01-07 00:00:00</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6599.978000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>-0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2573.000000</td>\n",
       "      <td>2021-05-23 00:00:00</td>\n",
       "      <td>2021-05-27 00:00:00</td>\n",
       "      <td>17.340000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.760800</td>\n",
       "      <td>6.480000</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5143.000000</td>\n",
       "      <td>2022-07-03 00:00:00</td>\n",
       "      <td>2022-07-04 00:00:00</td>\n",
       "      <td>53.970000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.694000</td>\n",
       "      <td>19.980000</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7668.000000</td>\n",
       "      <td>2023-05-18 00:00:00</td>\n",
       "      <td>2023-05-20 00:00:00</td>\n",
       "      <td>207.350000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>29.245000</td>\n",
       "      <td>73.950000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10194.000000</td>\n",
       "      <td>2023-12-30 00:00:00</td>\n",
       "      <td>2024-01-05 00:00:00</td>\n",
       "      <td>22638.480000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8399.976000</td>\n",
       "      <td>7546.160000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2941.568558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>621.061889</td>\n",
       "      <td>2.213594</td>\n",
       "      <td>0.206894</td>\n",
       "      <td>235.881124</td>\n",
       "      <td>191.882709</td>\n",
       "      <td>0.232254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Row_ID                     Order_Date  \\\n",
       "count  11737.000000                          11737   \n",
       "mean    5125.508307  2022-05-03 18:51:33.601431040   \n",
       "min        1.000000            2020-01-03 00:00:00   \n",
       "25%     2573.000000            2021-05-23 00:00:00   \n",
       "50%     5143.000000            2022-07-03 00:00:00   \n",
       "75%     7668.000000            2023-05-18 00:00:00   \n",
       "max    10194.000000            2023-12-30 00:00:00   \n",
       "std     2941.568558                            NaN   \n",
       "\n",
       "                           Ship_Date         Sales      Quantity  \\\n",
       "count                          11737  11737.000000  11737.000000   \n",
       "mean   2022-05-07 12:18:13.158387712    228.085882      3.778734   \n",
       "min              2020-01-07 00:00:00      0.444000      1.000000   \n",
       "25%              2021-05-27 00:00:00     17.340000      2.000000   \n",
       "50%              2022-07-04 00:00:00     53.970000      3.000000   \n",
       "75%              2023-05-20 00:00:00    207.350000      5.000000   \n",
       "max              2024-01-05 00:00:00  22638.480000     14.000000   \n",
       "std                              NaN    621.061889      2.213594   \n",
       "\n",
       "           Discount        Profit  unit_list_price    % utilidad  \n",
       "count  11737.000000  11737.000000     11737.000000  11737.000000  \n",
       "mean       0.156655     29.074615        75.921766      0.185404  \n",
       "min        0.000000  -6599.978000         0.990000     -0.630000  \n",
       "25%        0.000000      1.760800         6.480000      0.060000  \n",
       "50%        0.200000      8.694000        19.980000      0.260000  \n",
       "75%        0.200000     29.245000        73.950000      0.330000  \n",
       "max        0.800000   8399.976000      7546.160000      0.500000  \n",
       "std        0.206894    235.881124       191.882709      0.232254  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876fc5f",
   "metadata": {},
   "source": [
    "### *Returns*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9711eff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Order_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Productos devueltos",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cc7e91a1-4fee-46b0-a4d4-ddc67b5f7651",
       "rows": [
        [
         "0",
         "US-2020-100762",
         "4"
        ],
        [
         "1",
         "US-2020-100867",
         "1"
        ],
        [
         "2",
         "US-2020-102652",
         "4"
        ],
        [
         "3",
         "US-2020-103373",
         "1"
        ],
        [
         "4",
         "US-2020-103744",
         "2"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Productos devueltos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-2020-100762</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-2020-100867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-2020-102652</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-2020-103373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-2020-103744</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Order_ID  Productos devueltos\n",
       "0  US-2020-100762                    4\n",
       "1  US-2020-100867                    1\n",
       "2  US-2020-102652                    4\n",
       "3  US-2020-103373                    1\n",
       "4  US-2020-103744                    2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar archivo de \"Returns\"\n",
    "\n",
    "returns = pd.read_excel('Returns.xlsx')\n",
    "\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebf1fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 296 entries, 0 to 295\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Order_ID             296 non-null    object\n",
      " 1   Productos devueltos  296 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "returns.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c7a13fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Productos devueltos",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "080d5f51-6612-46b9-8f9a-7c264fac279b",
       "rows": [
        [
         "count",
         "296.0"
        ],
        [
         "mean",
         "2.7027027027027026"
        ],
        [
         "std",
         "1.8990076247272765"
        ],
        [
         "min",
         "1.0"
        ],
        [
         "25%",
         "1.0"
        ],
        [
         "50%",
         "2.0"
        ],
        [
         "75%",
         "3.0"
        ],
        [
         "max",
         "14.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Productos devueltos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>296.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Productos devueltos\n",
       "count           296.000000\n",
       "mean              2.702703\n",
       "std               1.899008\n",
       "min               1.000000\n",
       "25%               1.000000\n",
       "50%               2.000000\n",
       "75%               3.000000\n",
       "max              14.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329ed41",
   "metadata": {},
   "source": [
    "### *Costumer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19dcce36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Customer_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Customer_Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "monthly_salary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "marital_status [1:married/ 0:Single]",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "credit score",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d00c2476-e4e5-410c-af5f-590a3356b237",
       "rows": [
        [
         "0",
         "AA-10315",
         "Alex Avila",
         "6349",
         "32",
         "1",
         "500"
        ],
        [
         "1",
         "AA-10375",
         "Allen Armold",
         "5374",
         "26",
         "0",
         "630"
        ],
        [
         "2",
         "AA-10480",
         "Andrew Allen",
         "9611",
         "44",
         "1",
         "780"
        ],
        [
         "3",
         "AA-10645",
         "Anna Andreadi",
         "7025",
         "43",
         "1",
         "450"
        ],
        [
         "4",
         "AB-10015",
         "Aaron Bergman",
         "3331",
         "28",
         "1",
         "490"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Customer_Name</th>\n",
       "      <th>monthly_salary</th>\n",
       "      <th>age</th>\n",
       "      <th>marital_status [1:married/ 0:Single]</th>\n",
       "      <th>credit score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA-10315</td>\n",
       "      <td>Alex Avila</td>\n",
       "      <td>6349</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA-10375</td>\n",
       "      <td>Allen Armold</td>\n",
       "      <td>5374</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA-10480</td>\n",
       "      <td>Andrew Allen</td>\n",
       "      <td>9611</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA-10645</td>\n",
       "      <td>Anna Andreadi</td>\n",
       "      <td>7025</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB-10015</td>\n",
       "      <td>Aaron Bergman</td>\n",
       "      <td>3331</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Customer_ID  Customer_Name monthly_salary  age  \\\n",
       "0    AA-10315     Alex Avila           6349   32   \n",
       "1    AA-10375   Allen Armold           5374   26   \n",
       "2    AA-10480   Andrew Allen           9611   44   \n",
       "3    AA-10645  Anna Andreadi           7025   43   \n",
       "4    AB-10015  Aaron Bergman           3331   28   \n",
       "\n",
       "   marital_status [1:married/ 0:Single]  credit score  \n",
       "0                                     1           500  \n",
       "1                                     0           630  \n",
       "2                                     1           780  \n",
       "3                                     1           450  \n",
       "4                                     1           490  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar archivo de \"Costumer\"\n",
    "\n",
    "costumer = pd.read_excel('Costumer.xlsx')\n",
    "\n",
    "costumer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22f0f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 804 entries, 0 to 803\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   Customer_ID                           804 non-null    object\n",
      " 1   Customer_Name                         804 non-null    object\n",
      " 2   monthly_salary                        804 non-null    object\n",
      " 3   age                                   804 non-null    int64 \n",
      " 4   marital_status [1:married/ 0:Single]  804 non-null    int64 \n",
      " 5   credit score                          804 non-null    int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 37.8+ KB\n"
     ]
    }
   ],
   "source": [
    "costumer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e421032f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "marital_status [1:married/ 0:Single]",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "credit score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5fb9de9f-c113-4ad7-be43-29636f230a9a",
       "rows": [
        [
         "count",
         "804.0",
         "804.0",
         "804.0"
        ],
        [
         "mean",
         "38.41542288557214",
         "0.513681592039801",
         "557.9477611940298"
        ],
        [
         "std",
         "10.901531919965013",
         "0.5001238980833399",
         "148.99210492497676"
        ],
        [
         "min",
         "26.0",
         "0.0",
         "300.0"
        ],
        [
         "25%",
         "32.0",
         "0.0",
         "420.0"
        ],
        [
         "50%",
         "38.0",
         "1.0",
         "560.0"
        ],
        [
         "75%",
         "44.0",
         "1.0",
         "690.0"
        ],
        [
         "max",
         "260.0",
         "1.0",
         "800.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital_status [1:married/ 0:Single]</th>\n",
       "      <th>credit score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>804.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.415423</td>\n",
       "      <td>0.513682</td>\n",
       "      <td>557.947761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.901532</td>\n",
       "      <td>0.500124</td>\n",
       "      <td>148.992105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>420.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>560.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>260.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  marital_status [1:married/ 0:Single]  credit score\n",
       "count  804.000000                            804.000000    804.000000\n",
       "mean    38.415423                              0.513682    557.947761\n",
       "std     10.901532                              0.500124    148.992105\n",
       "min     26.000000                              0.000000    300.000000\n",
       "25%     32.000000                              0.000000    420.000000\n",
       "50%     38.000000                              1.000000    560.000000\n",
       "75%     44.000000                              1.000000    690.000000\n",
       "max    260.000000                              1.000000    800.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costumer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b6701",
   "metadata": {},
   "source": [
    "### *Regional manager*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b068f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Regional_Manager",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "7a4c970d-a77b-4d64-957d-5a590c5c6d94",
       "rows": [
        [
         "0",
         "Chuck Magee",
         "East"
        ],
        [
         "1",
         "Fred Suzuki",
         "South"
        ],
        [
         "2",
         "Roxanne Rodriguez",
         "Central"
        ],
        [
         "3",
         "Sadie Pawthorne",
         "West"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regional_Manager</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chuck Magee</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fred Suzuki</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roxanne Rodriguez</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sadie Pawthorne</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Regional_Manager   Region\n",
       "0        Chuck Magee     East\n",
       "1        Fred Suzuki    South\n",
       "2  Roxanne Rodriguez  Central\n",
       "3    Sadie Pawthorne     West"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar archivo de \"Regional_manager\"\n",
    "\n",
    "rm = pd.read_excel('Regional_manager.xlsx')\n",
    "\n",
    "rm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d326d37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Regional_Manager  4 non-null      object\n",
      " 1   Region            4 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 196.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "rm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d6ca84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Regional_Manager",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Region",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "e443ab0a-5602-40ed-9050-cb5e2f6e2169",
       "rows": [
        [
         "count",
         "4",
         "4"
        ],
        [
         "unique",
         "4",
         "4"
        ],
        [
         "top",
         "Chuck Magee",
         "East"
        ],
        [
         "freq",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regional_Manager</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Chuck Magee</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Regional_Manager Region\n",
       "count                 4      4\n",
       "unique                4      4\n",
       "top         Chuck Magee   East\n",
       "freq                  1      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e80738",
   "metadata": {},
   "source": [
    "### *Product*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c86ab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Product_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Categoría",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sub-Categoría",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product_Name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4549acd0-1884-4040-a26e-6e0e18a45b63",
       "rows": [
        [
         "0",
         "FUR-BO-10000112",
         "Furniture",
         "Bookcases",
         "Bush Birmingham Collection Bookcase, Dark Cherry"
        ],
        [
         "1",
         "FUR-BO-10000330",
         "Furniture",
         "Bookcases",
         "Sauder Camden County Barrister Bookcase, Planked Cherry Finish"
        ],
        [
         "2",
         "FUR-BO-10000362",
         "Furniture",
         "Bookcases",
         "Sauder Inglewood Library Bookcases"
        ],
        [
         "3",
         "FUR-BO-10000468",
         "Furniture",
         "Bookcases",
         "O'Sullivan 2-Shelf Heavy-Duty Bookcases"
        ],
        [
         "4",
         "FUR-BO-10000711",
         "Furniture",
         "Bookcases",
         "Hon Metal Bookcases, Gray"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Categoría</th>\n",
       "      <th>Sub-Categoría</th>\n",
       "      <th>Product_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FUR-BO-10000112</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Birmingham Collection Bookcase, Dark Cherry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FUR-BO-10000330</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Sauder Camden County Barrister Bookcase, Plank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FUR-BO-10000362</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Sauder Inglewood Library Bookcases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FUR-BO-10000468</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>O'Sullivan 2-Shelf Heavy-Duty Bookcases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FUR-BO-10000711</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Hon Metal Bookcases, Gray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product_ID  Categoría Sub-Categoría  \\\n",
       "0  FUR-BO-10000112  Furniture     Bookcases   \n",
       "1  FUR-BO-10000330  Furniture     Bookcases   \n",
       "2  FUR-BO-10000362  Furniture     Bookcases   \n",
       "3  FUR-BO-10000468  Furniture     Bookcases   \n",
       "4  FUR-BO-10000711  Furniture     Bookcases   \n",
       "\n",
       "                                        Product_Name  \n",
       "0   Bush Birmingham Collection Bookcase, Dark Cherry  \n",
       "1  Sauder Camden County Barrister Bookcase, Plank...  \n",
       "2                 Sauder Inglewood Library Bookcases  \n",
       "3            O'Sullivan 2-Shelf Heavy-Duty Bookcases  \n",
       "4                          Hon Metal Bookcases, Gray  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar archivo de \"product\"\n",
    "\n",
    "product = pd.read_excel('Product.xlsx')\n",
    "\n",
    "product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84debe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1862 entries, 0 to 1861\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Product_ID     1862 non-null   object\n",
      " 1   Categoría      1862 non-null   object\n",
      " 2   Sub-Categoría  1862 non-null   object\n",
      " 3   Product_Name   1862 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 58.3+ KB\n"
     ]
    }
   ],
   "source": [
    "product.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab3b7de",
   "metadata": {},
   "source": [
    "## **2.1 Segmentación de clientes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5effa9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 configuraciones:\n",
      "   k pca_var       init  n_init  silhouette  davies_bouldin  \\\n",
      "0  2     0.9  k-means++      20    0.295570        1.581067   \n",
      "1  2     0.9  k-means++      50    0.295570        1.581067   \n",
      "2  3     0.9  k-means++      20    0.294895        1.421296   \n",
      "3  3     0.9  k-means++      50    0.294895        1.421296   \n",
      "4  2    0.95  k-means++      20    0.279683        1.648649   \n",
      "5  2    0.95  k-means++      50    0.279683        1.648649   \n",
      "6  3    0.95  k-means++      20    0.278000        1.487754   \n",
      "7  3    0.95  k-means++      50    0.278000        1.487754   \n",
      "8  2    None  k-means++      20    0.270127        1.695127   \n",
      "9  2    None  k-means++      50    0.270127        1.695127   \n",
      "\n",
      "   calinski_harabasz       inertia  stability_ari_mean  stability_ari_std  \n",
      "0         186.674953  12396.032206            1.000000           0.000000  \n",
      "1         186.674953  12396.032206            1.000000           0.000000  \n",
      "2         174.279296  10647.882839            1.000000           0.000000  \n",
      "3         174.279296  10647.882839            1.000000           0.000000  \n",
      "4         174.802077  13255.594096            1.000000           0.000000  \n",
      "5         174.802077  13255.594096            1.000000           0.000000  \n",
      "6         161.425088  11506.824806            0.998378           0.003244  \n",
      "7         161.425088  11506.824806            0.998378           0.003244  \n",
      "8         166.567430  13920.371085            1.000000           0.000000  \n",
      "9         166.567430  13920.371085            1.000000           0.000000  \n",
      "\n",
      "Guardado: model_selection_results.csv\n",
      "\n",
      "Mejor configuración elegida:\n",
      "{'k': 2, 'pca_var': 0.9, 'init': 'k-means++', 'n_init': 20, 'silhouette': 0.295570427529028, 'davies_bouldin': 1.5810672476660614, 'calinski_harabasz': 186.67495266443856, 'inertia': 12396.032206215754, 'stability_ari_mean': 1.0, 'stability_ari_std': 0.0}\n",
      "\n",
      "Métricas del modelo final:\n",
      "{'k': 2, 'pca_var': 0.9, 'silhouette': 0.295570427529028, 'davies_bouldin': 1.5810672476660614, 'calinski_harabasz': 186.67495266443856, 'inertia': 12396.032206215754}\n",
      "\n",
      "Perfil de clusters (ordenado por sales_share):\n",
      "   cluster  customers         sales       profit  avg_margin     avg_aov  \\\n",
      "1        1        638  2.179280e+06  423766.1007     0.18393  517.988689   \n",
      "0        0        166  4.480096e+05  -82517.3389    -0.17761  476.737920   \n",
      "\n",
      "   avg_freq  avg_recency  avg_discount  pct_lines_discounted  return_rate  \\\n",
      "1  6.564263   136.208464      0.136844              0.480458     0.061576   \n",
      "0  5.542169   186.873494      0.233016              0.701766     0.053131   \n",
      "\n",
      "   lead_time  sales_share  profit_share  margin_weighted  \n",
      "1   3.940703     0.829478       1.24181         0.194452  \n",
      "0   4.012984     0.170522      -0.24181        -0.184187  \n",
      "\n",
      "Guardados:\n",
      "- customer_segmentation_output.csv\n",
      "- cluster_profile_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2.1 Segmentación de clientes \n",
    "# - Numeric-only KMeans \n",
    "# - Winsorization p1-p99\n",
    "# - Signed-log profit\n",
    "# - PCA opcional + tuning hiperparámetros\n",
    "# - Métricas: Silhouette, DBI, CH, Inertia + Estabilidad (ARI)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Configuración\n",
    "# ---------------------------\n",
    "FILES = {\n",
    "    \"sales\": \"Sales.xlsx\",\n",
    "    \"returns\": \"Returns.xlsx\",\n",
    "    \"customer\": \"Costumer.xlsx\",         \n",
    "    \"rm\": \"Regional_manager.xlsx\",\n",
    "    \"product\": \"Product.xlsx\"\n",
    "}\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "COL = {\n",
    "    \"customer_id\": \"Customer_ID\",\n",
    "    \"order_id\": \"Order_ID\",\n",
    "    \"order_date\": \"Order_Date\",\n",
    "    \"ship_date\": \"Ship_Date\",\n",
    "    \"sales\": \"Sales\",\n",
    "    \"profit\": \"Profit\",\n",
    "    \"discount\": \"Discount\",\n",
    "    \"qty\": \"Quantity\",\n",
    "    \"ship_mode\": \"Ship_Mode\",\n",
    "    \"region\": \"Region\",\n",
    "    \"country\": \"Country/Region\",\n",
    "    \"state\": \"State/Province\",\n",
    "    \"city\": \"City\",\n",
    "    \"product_id\": \"Product_ID\",\n",
    "    \"category\": \"Productos.Category\",\n",
    "    \"subcat\": \"Productos.Sub-Category\",\n",
    "    \"returned_units\": \"Productos devueltos\",   \n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers\n",
    "# ---------------------------\n",
    "def to_num(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Converts series to numeric safely.\"\"\"\n",
    "    return pd.to_numeric(series, errors=\"coerce\")\n",
    "\n",
    "def signed_log1p(x: pd.Series) -> pd.Series:\n",
    "    \"\"\"Signed log transform: sign(x)*log1p(abs(x)). Keeps negative signal.\"\"\"\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    return np.sign(x) * np.log1p(np.abs(x))\n",
    "\n",
    "def winsorize_series(s: pd.Series, p_low=0.01, p_high=0.99) -> pd.Series:\n",
    "    \"\"\"Caps series at given percentiles.\"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    lo = s.quantile(p_low)\n",
    "    hi = s.quantile(p_high)\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "def safe_col(df: pd.DataFrame, colname: str) -> bool:\n",
    "    return colname in df.columns\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Cargar datos\n",
    "# ---------------------------\n",
    "sales = pd.read_excel(FILES[\"sales\"])\n",
    "returns = pd.read_excel(FILES[\"returns\"])\n",
    "customer = pd.read_excel(FILES[\"customer\"])\n",
    "rm = pd.read_excel(FILES[\"rm\"])\n",
    "product = pd.read_excel(FILES[\"product\"])\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Limpieza mínima / consistencia\n",
    "# ---------------------------\n",
    "\n",
    "# Dedup customer\n",
    "if safe_col(customer, COL[\"customer_id\"]):\n",
    "    customer = customer.drop_duplicates(subset=[COL[\"customer_id\"]]).copy()\n",
    "\n",
    "# Dedup product (si hay duplicados por Product_ID)\n",
    "if safe_col(product, COL[\"product_id\"]):\n",
    "    sort_cols = [COL[\"product_id\"]]\n",
    "    if \"Product_Name\" in product.columns:\n",
    "        sort_cols.append(\"Product_Name\")\n",
    "    product = (\n",
    "        product.sort_values(sort_cols)\n",
    "               .drop_duplicates(subset=[COL[\"product_id\"]], keep=\"first\")\n",
    "               .copy()\n",
    "    )\n",
    "\n",
    "# Tipos de datos en sales\n",
    "for c in [COL[\"sales\"], COL[\"profit\"], COL[\"discount\"], COL[\"qty\"]]:\n",
    "    if safe_col(sales, c):\n",
    "        sales[c] = to_num(sales[c])\n",
    "\n",
    "# Fechas\n",
    "if safe_col(sales, COL[\"order_date\"]):\n",
    "    sales[COL[\"order_date\"]] = pd.to_datetime(sales[COL[\"order_date\"]], errors=\"coerce\")\n",
    "if safe_col(sales, COL[\"ship_date\"]):\n",
    "    sales[COL[\"ship_date\"]] = pd.to_datetime(sales[COL[\"ship_date\"]], errors=\"coerce\")\n",
    "\n",
    "# Discount clean\n",
    "if safe_col(sales, COL[\"discount\"]):\n",
    "    sales[\"Discount_clean\"] = np.where(sales[COL[\"discount\"]] > 1, sales[COL[\"discount\"]] / 100, sales[COL[\"discount\"]])\n",
    "else:\n",
    "    sales[\"Discount_clean\"] = np.nan\n",
    "\n",
    "# Lead time (si no existe ya)\n",
    "if safe_col(sales, COL[\"order_date\"]) and safe_col(sales, COL[\"ship_date\"]):\n",
    "    sales[\"lead_time_days\"] = (sales[COL[\"ship_date\"]] - sales[COL[\"order_date\"]]).dt.days\n",
    "else:\n",
    "    sales[\"lead_time_days\"] = np.nan\n",
    "\n",
    "# Returns -> asegurar 1 fila por orden\n",
    "# Si returns viene con múltiples filas por Order_ID, se agrupa.\n",
    "if safe_col(returns, COL[\"order_id\"]):\n",
    "    if safe_col(returns, COL[\"returned_units\"]):\n",
    "        ret_order = (returns.groupby(COL[\"order_id\"], as_index=False)\n",
    "                     .agg(productos_devueltos=(COL[\"returned_units\"], \"sum\")))\n",
    "    else:\n",
    "        # fallback: si no existe 'Productos devueltos', asume flag=1 por fila\n",
    "        ret_order = (returns.groupby(COL[\"order_id\"], as_index=False)\n",
    "                     .size().rename(columns={\"size\": \"productos_devueltos\"}))\n",
    "    ret_order[\"returned_flag\"] = (ret_order[\"productos_devueltos\"] > 0).astype(int)\n",
    "else:\n",
    "    ret_order = pd.DataFrame(columns=[COL[\"order_id\"], \"productos_devueltos\", \"returned_flag\"])\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Unir información (df transaccional)\n",
    "# ---------------------------\n",
    "df = sales.copy()\n",
    "\n",
    "# Merge product\n",
    "if safe_col(df, COL[\"product_id\"]) and safe_col(product, COL[\"product_id\"]):\n",
    "    # Trae categoría y subcategoría si existen\n",
    "    prod_cols = [COL[\"product_id\"]]\n",
    "    for extra in [COL[\"category\"], COL[\"subcat\"], \"Product_Name\"]:\n",
    "        if safe_col(product, extra):\n",
    "            prod_cols.append(extra)\n",
    "    df = df.merge(product[prod_cols], on=COL[\"product_id\"], how=\"left\")\n",
    "\n",
    "# Merge customer\n",
    "if safe_col(df, COL[\"customer_id\"]) and safe_col(customer, COL[\"customer_id\"]):\n",
    "    df = df.merge(customer, on=COL[\"customer_id\"], how=\"left\")\n",
    "\n",
    "# Merge returns\n",
    "if safe_col(df, COL[\"order_id\"]) and safe_col(ret_order, COL[\"order_id\"]):\n",
    "    df = df.merge(ret_order[[COL[\"order_id\"], \"returned_flag\", \"productos_devueltos\"]], on=COL[\"order_id\"], how=\"left\")\n",
    "else:\n",
    "    df[\"returned_flag\"] = 0\n",
    "    df[\"productos_devueltos\"] = 0\n",
    "\n",
    "df[\"returned_flag\"] = df.get(\"returned_flag\", 0).fillna(0).astype(int)\n",
    "df[\"productos_devueltos\"] = df.get(\"productos_devueltos\", 0).fillna(0)\n",
    "\n",
    "# Merge regional manager\n",
    "if safe_col(df, COL[\"region\"]) and safe_col(rm, COL[\"region\"]):\n",
    "    df = df.merge(rm, on=COL[\"region\"], how=\"left\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Tabla a nivel ORDEN\n",
    "# ---------------------------\n",
    "group_cols = [COL[\"customer_id\"], COL[\"order_id\"]]\n",
    "order_tbl = (\n",
    "    df.groupby(group_cols, as_index=False)\n",
    "      .agg(\n",
    "          order_date=(COL[\"order_date\"], \"min\"),\n",
    "          ship_date=(COL[\"ship_date\"], \"min\") if safe_col(df, COL[\"ship_date\"]) else (\"Discount_clean\", \"count\"),\n",
    "          sales=(COL[\"sales\"], \"sum\"),\n",
    "          profit=(COL[\"profit\"], \"sum\"),\n",
    "          qty=(COL[\"qty\"], \"sum\"),\n",
    "          discount_mean=(\"Discount_clean\", \"mean\"),\n",
    "          discount_median=(\"Discount_clean\", \"median\"),\n",
    "          lead_time_mean=(\"lead_time_days\", \"mean\"),\n",
    "          returned_flag=(\"returned_flag\", \"max\"),\n",
    "          productos_devueltos=(\"productos_devueltos\", \"max\"),\n",
    "      )\n",
    ")\n",
    "\n",
    "# Campos “preferidos” por cliente (opcionales para perfil; NO para clustering)\n",
    "def mode_or_first(s):\n",
    "    m = s.mode()\n",
    "    return m.iloc[0] if len(m) else s.iloc[0]\n",
    "\n",
    "for col in [COL[\"ship_mode\"], COL[\"region\"], COL[\"country\"]]:\n",
    "    if safe_col(df, col):\n",
    "        tmp = (df.groupby(group_cols, as_index=False)[col].agg(mode_or_first))\n",
    "        order_tbl = order_tbl.merge(tmp, on=group_cols, how=\"left\")\n",
    "\n",
    "# Fecha referencia recencia\n",
    "max_date = order_tbl[\"order_date\"].max()\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Customer 360 (1 fila por cliente)\n",
    "# ---------------------------\n",
    "cust = (\n",
    "    order_tbl.groupby(COL[\"customer_id\"], as_index=False)\n",
    "             .agg(\n",
    "                 frequency_orders=(COL[\"order_id\"], \"nunique\"),\n",
    "                 monetary_sales=(\"sales\", \"sum\"),\n",
    "                 monetary_profit=(\"profit\", \"sum\"),\n",
    "                 units_total=(\"qty\", \"sum\"),\n",
    "                 avg_discount=(\"discount_mean\", \"mean\"),\n",
    "                 med_discount=(\"discount_median\", \"mean\"),\n",
    "                 lead_time_mean=(\"lead_time_mean\", \"mean\"),\n",
    "                 return_order_rate=(\"returned_flag\", \"mean\"),\n",
    "                 avg_products_returned=(\"productos_devueltos\", \"mean\"),\n",
    "                 last_order=(\"order_date\", \"max\"),\n",
    "                 first_order=(\"order_date\", \"min\"),\n",
    "             )\n",
    ")\n",
    "\n",
    "cust[\"aov\"] = cust[\"monetary_sales\"] / cust[\"frequency_orders\"].replace(0, np.nan)\n",
    "cust[\"margin_pct\"] = cust[\"monetary_profit\"] / cust[\"monetary_sales\"].replace(0, np.nan)\n",
    "cust[\"units_per_order\"] = cust[\"units_total\"] / cust[\"frequency_orders\"].replace(0, np.nan)\n",
    "cust[\"recency_days\"] = (max_date - cust[\"last_order\"]).dt.days\n",
    "cust[\"tenure_days\"] = (cust[\"last_order\"] - cust[\"first_order\"]).dt.days\n",
    "\n",
    "# Diversidad / concentración desde df (si existen Category/Subcat)\n",
    "if safe_col(df, COL[\"category\"]) or safe_col(df, COL[\"subcat\"]):\n",
    "    div = {COL[\"product_id\"]: \"nunique\"}\n",
    "    if safe_col(df, COL[\"category\"]):\n",
    "        div[COL[\"category\"]] = \"nunique\"\n",
    "    if safe_col(df, COL[\"subcat\"]):\n",
    "        div[COL[\"subcat\"]] = \"nunique\"\n",
    "\n",
    "    diversity = (\n",
    "        df.groupby(COL[\"customer_id\"], as_index=False)\n",
    "          .agg(\n",
    "              product_diversity=(COL[\"product_id\"], \"nunique\"),\n",
    "              category_diversity=(COL[\"category\"], \"nunique\") if safe_col(df, COL[\"category\"]) else (COL[\"product_id\"], \"count\"),\n",
    "              subcat_diversity=(COL[\"subcat\"], \"nunique\") if safe_col(df, COL[\"subcat\"]) else (COL[\"product_id\"], \"count\"),\n",
    "          )\n",
    "    )\n",
    "else:\n",
    "    diversity = pd.DataFrame({COL[\"customer_id\"]: cust[COL[\"customer_id\"]],\n",
    "                             \"product_diversity\": 0,\n",
    "                             \"category_diversity\": 0,\n",
    "                             \"subcat_diversity\": 0})\n",
    "\n",
    "# Top category share\n",
    "if safe_col(df, COL[\"category\"]):\n",
    "    cat_sales = (df.groupby([COL[\"customer_id\"], COL[\"category\"]], as_index=False)[COL[\"sales\"]].sum())\n",
    "    cat_sales[\"cat_share\"] = cat_sales[COL[\"sales\"]] / cat_sales.groupby(COL[\"customer_id\"])[COL[\"sales\"]].transform(\"sum\")\n",
    "    top_cat = (cat_sales.sort_values([COL[\"customer_id\"], \"cat_share\"], ascending=[True, False])\n",
    "                      .drop_duplicates(COL[\"customer_id\"])\n",
    "                      .rename(columns={\"cat_share\": \"top_category_share\"})[[COL[\"customer_id\"], \"top_category_share\"]])\n",
    "else:\n",
    "    top_cat = pd.DataFrame({COL[\"customer_id\"]: cust[COL[\"customer_id\"]], \"top_category_share\": 1.0})\n",
    "\n",
    "# Discount behavior por línea\n",
    "disc_line = (\n",
    "    df.assign(is_disc=(df[\"Discount_clean\"] > 0).astype(int))\n",
    "      .groupby(COL[\"customer_id\"], as_index=False)\n",
    "      .agg(\n",
    "          pct_lines_discounted=(\"is_disc\", \"mean\"),\n",
    "          discount_std=(\"Discount_clean\", \"std\"),\n",
    "          discount_p90=(\"Discount_clean\", lambda s: np.nanpercentile(s, 90)),\n",
    "      )\n",
    ")\n",
    "disc_line[\"discount_std\"] = disc_line[\"discount_std\"].fillna(0)\n",
    "\n",
    "# Unir todo\n",
    "cust = cust.merge(diversity, on=COL[\"customer_id\"], how=\"left\")\n",
    "cust = cust.merge(top_cat, on=COL[\"customer_id\"], how=\"left\")\n",
    "cust = cust.merge(disc_line, on=COL[\"customer_id\"], how=\"left\")\n",
    "\n",
    "# Traer demografía si existe (ajusta nombres según tu archivo)\n",
    "# Intentamos columnas típicas; si no existen, no rompe.\n",
    "demo_cols = [\n",
    "    \"monthly_salary\",\n",
    "    \"age\",\n",
    "    \"marital_status [1:married/ 0:Single]\",\n",
    "    \"credit score\"\n",
    "]\n",
    "for dc in demo_cols:\n",
    "    if dc in customer.columns and dc not in cust.columns:\n",
    "        # ya vienen por merge previo si df los tenía; por seguridad, merge directo desde customer\n",
    "        pass\n",
    "\n",
    "if safe_col(customer, COL[\"customer_id\"]):\n",
    "    keep_demo = [COL[\"customer_id\"]] + [c for c in demo_cols if c in customer.columns]\n",
    "    cust = cust.merge(customer[keep_demo], on=COL[\"customer_id\"], how=\"left\")\n",
    "\n",
    "# Defaults seguros\n",
    "cust[\"top_category_share\"] = cust[\"top_category_share\"].fillna(1.0)\n",
    "cust[\"pct_lines_discounted\"] = cust[\"pct_lines_discounted\"].fillna(0.0)\n",
    "cust[\"discount_std\"] = cust[\"discount_std\"].fillna(0.0)\n",
    "cust[\"discount_p90\"] = cust[\"discount_p90\"].fillna(0.0)\n",
    "cust[\"lead_time_mean\"] = cust[\"lead_time_mean\"].fillna(cust[\"lead_time_mean\"].median())\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Transformaciones para mejorar clustering\n",
    "# - winsorización en variables sesgadas\n",
    "# - signed-log profit\n",
    "# - log en ventas/frecuencia/diversidad\n",
    "# ---------------------------\n",
    "\n",
    "# Winsorizar (cap p1-p99) variables típicamente con outliers\n",
    "for colw in [\"monetary_sales\", \"frequency_orders\", \"aov\", \"units_per_order\", \"units_total\"]:\n",
    "    if colw in cust.columns:\n",
    "        cust[colw] = winsorize_series(cust[colw], 0.01, 0.99)\n",
    "\n",
    "# Profit: mantener negativos con signed log (mejora robustez)\n",
    "cust[\"profit_signed_log\"] = signed_log1p(cust[\"monetary_profit\"])\n",
    "\n",
    "# Logs para heavy tails (evita duplicar: usaremos logs en lugar de raws donde aplique)\n",
    "cust[\"sales_log\"] = np.log1p(cust[\"monetary_sales\"].clip(lower=0))\n",
    "cust[\"freq_log\"] = np.log1p(cust[\"frequency_orders\"].clip(lower=0))\n",
    "cust[\"proddiv_log\"] = np.log1p(cust[\"product_diversity\"].clip(lower=0))\n",
    "cust[\"subcatdiv_log\"] = np.log1p(cust[\"subcat_diversity\"].clip(lower=0))\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Dataset final NUMÉRICO (para KMeans)\n",
    "# (Reducimos redundancia: preferimos logs + ratios)\n",
    "# ---------------------------\n",
    "num_features = [\n",
    "    \"recency_days\",\n",
    "    \"tenure_days\",\n",
    "    \"freq_log\",\n",
    "    \"sales_log\",\n",
    "    \"profit_signed_log\",\n",
    "    \"margin_pct\",\n",
    "    \"aov\",\n",
    "    \"units_per_order\",\n",
    "    \"avg_discount\",\n",
    "    \"med_discount\",\n",
    "    \"discount_std\",\n",
    "    \"discount_p90\",\n",
    "    \"pct_lines_discounted\",\n",
    "    \"lead_time_mean\",\n",
    "    \"return_order_rate\",\n",
    "    \"avg_products_returned\",\n",
    "    \"proddiv_log\",\n",
    "    \"subcatdiv_log\",\n",
    "    \"category_diversity\",\n",
    "    \"top_category_share\",\n",
    "]\n",
    "\n",
    "# Demografía si existe\n",
    "for dc in demo_cols:\n",
    "    if dc in cust.columns:\n",
    "        num_features.append(dc)\n",
    "\n",
    "# Coerción numérica\n",
    "for c in num_features:\n",
    "    cust[c] = pd.to_numeric(cust[c], errors=\"coerce\")\n",
    "\n",
    "X = cust[num_features].copy()\n",
    "\n",
    "# Preprocess numérico: imputar + escalar robusto\n",
    "preprocess = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "X_scaled = preprocess.fit_transform(X)\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Tuning hiperparámetros + métricas adicionales + estabilidad\n",
    "# ---------------------------\n",
    "\n",
    "def evaluate_config(Xmat, k, pca_var=None, init=\"k-means++\", n_init=50, seed=42):\n",
    "    # PCA opcional\n",
    "    Xuse = Xmat\n",
    "    pca_model = None\n",
    "    if pca_var is not None:\n",
    "        pca_model = PCA(n_components=pca_var, random_state=seed)\n",
    "        Xuse = pca_model.fit_transform(Xmat)\n",
    "\n",
    "    km = KMeans(\n",
    "        n_clusters=k,\n",
    "        init=init,\n",
    "        n_init=n_init,\n",
    "        max_iter=500,\n",
    "        random_state=seed\n",
    "    )\n",
    "    labels = km.fit_predict(Xuse)\n",
    "\n",
    "    # Métricas internas\n",
    "    sil = silhouette_score(Xuse, labels)\n",
    "    dbi = davies_bouldin_score(Xuse, labels)\n",
    "    ch = calinski_harabasz_score(Xuse, labels)\n",
    "    inertia = km.inertia_\n",
    "\n",
    "    return labels, sil, dbi, ch, inertia, pca_model\n",
    "\n",
    "def stability_ari(Xmat, k, pca_var=None, init=\"k-means++\", n_init=50, base_seed=42, seeds=(1, 7, 21, 99, 123)):\n",
    "    # Base\n",
    "    base_labels, *_ = evaluate_config(Xmat, k, pca_var=pca_var, init=init, n_init=n_init, seed=base_seed)\n",
    "\n",
    "    aris = []\n",
    "    for s in seeds:\n",
    "        lbl, *_ = evaluate_config(Xmat, k, pca_var=pca_var, init=init, n_init=n_init, seed=s)\n",
    "        aris.append(adjusted_rand_score(base_labels, lbl))\n",
    "    return float(np.mean(aris)), float(np.std(aris))\n",
    "\n",
    "# Grid (mantener razonable para tiempo)\n",
    "k_range = range(2, 11)\n",
    "pca_options = [None, 0.90, 0.95]          # None = sin PCA\n",
    "init_options = [\"k-means++\"]              # puedes agregar \"random\" si quieres\n",
    "n_init_options = [20, 50]\n",
    "\n",
    "rows = []\n",
    "for pca_var in pca_options:\n",
    "    for init in init_options:\n",
    "        for n_init in n_init_options:\n",
    "            for k in k_range:\n",
    "                labels, sil, dbi, ch, inertia, _ = evaluate_config(\n",
    "                    X_scaled, k, pca_var=pca_var, init=init, n_init=n_init, seed=RANDOM_STATE\n",
    "                )\n",
    "                ari_mean, ari_std = stability_ari(\n",
    "                    X_scaled, k, pca_var=pca_var, init=init, n_init=n_init, base_seed=RANDOM_STATE\n",
    "                )\n",
    "\n",
    "                rows.append({\n",
    "                    \"k\": k,\n",
    "                    \"pca_var\": \"None\" if pca_var is None else pca_var,\n",
    "                    \"init\": init,\n",
    "                    \"n_init\": n_init,\n",
    "                    \"silhouette\": sil,\n",
    "                    \"davies_bouldin\": dbi,\n",
    "                    \"calinski_harabasz\": ch,\n",
    "                    \"inertia\": inertia,\n",
    "                    \"stability_ari_mean\": ari_mean,\n",
    "                    \"stability_ari_std\": ari_std\n",
    "                })\n",
    "\n",
    "results = pd.DataFrame(rows)\n",
    "\n",
    "# Ranking sugerido (multi-criterio):\n",
    "# - maximizar silhouette\n",
    "# - minimizar davies_bouldin\n",
    "# - maximizar calinski_harabasz\n",
    "# - maximizar estabilidad (ARI)\n",
    "results_sorted = results.sort_values(\n",
    "    by=[\"silhouette\", \"stability_ari_mean\", \"davies_bouldin\", \"calinski_harabasz\"],\n",
    "    ascending=[False, False, True, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop 10 configuraciones:\")\n",
    "print(results_sorted.head(10))\n",
    "\n",
    "# Guardar tabla de selección (para anexar a presentación/justificación)\n",
    "results_sorted.to_csv(\"model_selection_results.csv\", index=False)\n",
    "print(\"\\nGuardado: model_selection_results.csv\")\n",
    "\n",
    "# Seleccionar la mejor configuración\n",
    "best = results_sorted.iloc[0].to_dict()\n",
    "best_k = int(best[\"k\"])\n",
    "best_pca = None if best[\"pca_var\"] == \"None\" else float(best[\"pca_var\"])\n",
    "best_init = best[\"init\"]\n",
    "best_n_init = int(best[\"n_init\"])\n",
    "\n",
    "print(\"\\nMejor configuración elegida:\")\n",
    "print(best)\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Entrenar modelo final con mejor configuración\n",
    "# ---------------------------\n",
    "final_labels, sil, dbi, ch, inertia, pca_model = evaluate_config(\n",
    "    X_scaled, best_k, pca_var=best_pca, init=best_init, n_init=best_n_init, seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "cust[\"cluster\"] = final_labels\n",
    "\n",
    "print(\"\\nMétricas del modelo final:\")\n",
    "print({\n",
    "    \"k\": best_k,\n",
    "    \"pca_var\": best[\"pca_var\"],\n",
    "    \"silhouette\": sil,\n",
    "    \"davies_bouldin\": dbi,\n",
    "    \"calinski_harabasz\": ch,\n",
    "    \"inertia\": inertia\n",
    "})\n",
    "\n",
    "# ---------------------------\n",
    "# 10) Perfilamiento de clusters (tabla ejecutiva)\n",
    "# ---------------------------\n",
    "profile = (\n",
    "    cust.groupby(\"cluster\")\n",
    "        .agg(\n",
    "            customers=(COL[\"customer_id\"], \"nunique\"),\n",
    "            sales=(\"monetary_sales\", \"sum\"),\n",
    "            profit=(\"monetary_profit\", \"sum\"),\n",
    "            avg_margin=(\"margin_pct\", \"mean\"),\n",
    "            avg_aov=(\"aov\", \"mean\"),\n",
    "            avg_freq=(\"frequency_orders\", \"mean\"),\n",
    "            avg_recency=(\"recency_days\", \"mean\"),\n",
    "            avg_discount=(\"avg_discount\", \"mean\"),\n",
    "            pct_lines_discounted=(\"pct_lines_discounted\", \"mean\"),\n",
    "            return_rate=(\"return_order_rate\", \"mean\"),\n",
    "            lead_time=(\"lead_time_mean\", \"mean\")\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "profile[\"sales_share\"] = profile[\"sales\"] / profile[\"sales\"].sum()\n",
    "profile[\"profit_share\"] = profile[\"profit\"] / profile[\"profit\"].sum()\n",
    "profile[\"margin_weighted\"] = profile[\"profit\"] / profile[\"sales\"].replace(0, np.nan)\n",
    "\n",
    "print(\"\\nPerfil de clusters (ordenado por sales_share):\")\n",
    "print(profile.sort_values(\"sales_share\", ascending=False))\n",
    "\n",
    "# ---------------------------\n",
    "# 11) Exportables\n",
    "# ---------------------------\n",
    "# output con features + cluster (para Power BI)\n",
    "out_cols = [COL[\"customer_id\"], \"cluster\"] + num_features\n",
    "cust[out_cols].to_csv(\"customer_segmentation_output.csv\", index=False)\n",
    "\n",
    "profile.to_csv(\"cluster_profile_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nGuardados:\")\n",
    "print(\"- customer_segmentation_output.csv\")\n",
    "print(\"- cluster_profile_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b06035",
   "metadata": {},
   "source": [
    "## **2.2. Aplicación con ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64481316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline Logistic ===\n",
      "{'model': 'Logistic', 'ROC_AUC': 0.7500490324267781, 'PR_AUC': 0.2051858865230908, 'Precision@thr': 0.22549019607843138, 'Recall@thr': 0.359375, 'F1@thr': 0.27710843373493976, 'ConfusionMatrix': [[877, 79], [41, 23]]}\n",
      "Top10% -> Recall: 0.359375 Precision: 0.22549019607843138 Threshold: 0.6866573672354702\n",
      "\n",
      "=== Tuned HGB (best) ===\n",
      "Best params: {'model__min_samples_leaf': 100, 'model__max_leaf_nodes': 15, 'model__max_depth': None, 'model__learning_rate': 0.02, 'model__l2_regularization': 0.1}\n",
      "{'model': 'HGB_tuned', 'ROC_AUC': 0.7439199790794979, 'PR_AUC': 0.2218842643352569, 'Precision@thr': 0.21568627450980393, 'Recall@thr': 0.34375, 'F1@thr': 0.26506024096385544, 'ConfusionMatrix': [[876, 80], [42, 22]]}\n",
      "Top10% -> Recall: 0.34375 Precision: 0.21568627450980393 Threshold: 0.122986843537903\n",
      "\n",
      "Classification report (HGB_tuned @Top10% threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       956\n",
      "           1       0.22      0.34      0.27        64\n",
      "\n",
      "    accuracy                           0.88      1020\n",
      "   macro avg       0.58      0.63      0.60      1020\n",
      "weighted avg       0.91      0.88      0.89      1020\n",
      "\n",
      "\n",
      "Lift (deciles, HGB):\n",
      "   decile    n  returns  return_rate  cum_returns  cum_return_share\n",
      "9       9  102       22     0.215686           22          0.343750\n",
      "8       8  102       11     0.107843           33          0.515625\n",
      "7       7  102        6     0.058824           39          0.609375\n",
      "6       6  102        7     0.068627           46          0.718750\n",
      "5       5  102        6     0.058824           52          0.812500\n",
      "4       4  102        3     0.029412           55          0.859375\n",
      "3       3  102        3     0.029412           58          0.906250\n",
      "2       2  102        4     0.039216           62          0.968750\n",
      "1       1  102        1     0.009804           63          0.984375\n",
      "0       0  102        1     0.009804           64          1.000000\n",
      "\n",
      "Guardados:\n",
      "- order_return_predictions.csv\n",
      "- lift_deciles_hgb.csv\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    f1_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 0) Config\n",
    "# ============================================================\n",
    "FILES = {\n",
    "    \"sales\": \"Sales.xlsx\",\n",
    "    \"returns\": \"Returns.xlsx\",\n",
    "    \"customer\": \"Costumer.xlsx\",\n",
    "    \"rm\": \"Regional_manager.xlsx\",\n",
    "    \"product\": \"Product.xlsx\",\n",
    "}\n",
    "\n",
    "COL = {\n",
    "    \"customer_id\": \"Customer_ID\",\n",
    "    \"order_id\": \"Order_ID\",\n",
    "    \"order_date\": \"Order_Date\",\n",
    "    \"sales\": \"Sales\",\n",
    "    \"profit\": \"Profit\",\n",
    "    \"discount\": \"Discount\",\n",
    "    \"qty\": \"Quantity\",\n",
    "    \"ship_mode\": \"Ship_Mode\",\n",
    "    \"region\": \"Region\",\n",
    "    \"country\": \"Country/Region\",\n",
    "    \"state\": \"State/Province\",\n",
    "    \"city\": \"City\",\n",
    "    \"product_id\": \"Product_ID\",\n",
    "    \"category\": \"Productos.Category\",\n",
    "    \"subcat\": \"Productos.Sub-Category\",\n",
    "    \"returned_units\": \"Productos devueltos\"\n",
    "}\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def safe_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return str(s).lower().replace(\"-\", \" \").replace(\"_\", \" \").strip()\n",
    "\n",
    "def find_category_col(df: pd.DataFrame):\n",
    "    cols = df.columns.tolist()\n",
    "    exact = {\"category\", \"productos category\", \"product category\"}\n",
    "    for c in cols:\n",
    "        if _norm(c) in exact:\n",
    "            return c\n",
    "    for c in cols:\n",
    "        cn = _norm(c)\n",
    "        if \"category\" in cn and \"sub\" not in cn:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def find_subcategory_col(df: pd.DataFrame):\n",
    "    cols = df.columns.tolist()\n",
    "    exact = {\"sub category\", \"sub-category\", \"subcategory\", \"productos sub category\", \"product sub category\"}\n",
    "    for c in cols:\n",
    "        if _norm(c) in exact:\n",
    "            return c\n",
    "    for c in cols:\n",
    "        cn = _norm(c)\n",
    "        if (\"subcategory\" in cn) or (\"sub\" in cn and \"category\" in cn):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def mode_or_first(x: pd.Series):\n",
    "    m = x.mode()\n",
    "    return m.iloc[0] if len(m) else x.iloc[0]\n",
    "\n",
    "# ============================================================\n",
    "# 1) Load\n",
    "# ============================================================\n",
    "sales = pd.read_excel(FILES[\"sales\"])\n",
    "returns = pd.read_excel(FILES[\"returns\"])\n",
    "customer = pd.read_excel(FILES[\"customer\"])\n",
    "rm = pd.read_excel(FILES[\"rm\"])\n",
    "product = pd.read_excel(FILES[\"product\"])\n",
    "\n",
    "# ============================================================\n",
    "# 2) Clean minimal\n",
    "# ============================================================\n",
    "customer = customer.drop_duplicates(subset=[COL[\"customer_id\"]]).copy()\n",
    "\n",
    "product = (product.sort_values([COL[\"product_id\"]] + ([\"Product_Name\"] if \"Product_Name\" in product.columns else []))\n",
    "           .drop_duplicates(subset=[COL[\"product_id\"]], keep=\"first\")\n",
    "           .copy())\n",
    "\n",
    "# Detect category/subcategory on Product and normalize names\n",
    "prod_cat_col = find_category_col(product)\n",
    "prod_subcat_col = find_subcategory_col(product)\n",
    "\n",
    "if prod_cat_col is not None and prod_subcat_col is not None and prod_cat_col == prod_subcat_col:\n",
    "    prod_subcat_col = prod_cat_col\n",
    "    for c in product.columns:\n",
    "        cn = _norm(c)\n",
    "        if c != prod_subcat_col and (\"category\" in cn and \"sub\" not in cn):\n",
    "            prod_cat_col = c\n",
    "            break\n",
    "\n",
    "rename_map = {}\n",
    "if prod_cat_col is not None:\n",
    "    rename_map[prod_cat_col] = COL[\"category\"]\n",
    "if prod_subcat_col is not None:\n",
    "    rename_map[prod_subcat_col] = COL[\"subcat\"]\n",
    "if rename_map:\n",
    "    product = product.rename(columns=rename_map)\n",
    "\n",
    "# Guarantee columns exist\n",
    "if COL[\"category\"] not in product.columns:\n",
    "    product[COL[\"category\"]] = np.nan\n",
    "if COL[\"subcat\"] not in product.columns:\n",
    "    product[COL[\"subcat\"]] = np.nan\n",
    "\n",
    "# Sales types\n",
    "sales[COL[\"order_date\"]] = pd.to_datetime(sales[COL[\"order_date\"]], errors=\"coerce\")\n",
    "for c in [COL[\"sales\"], COL[\"profit\"], COL[\"discount\"], COL[\"qty\"]]:\n",
    "    if c in sales.columns:\n",
    "        sales[c] = pd.to_numeric(sales[c], errors=\"coerce\")\n",
    "\n",
    "sales[\"Discount_clean\"] = np.where(\n",
    "    sales[COL[\"discount\"]] > 1,\n",
    "    sales[COL[\"discount\"]] / 100,\n",
    "    sales[COL[\"discount\"]]\n",
    ")\n",
    "\n",
    "# Returns label\n",
    "ret_order = (returns.groupby(COL[\"order_id\"], as_index=False)\n",
    "             .agg(productos_devueltos=(COL[\"returned_units\"], \"sum\")))\n",
    "ret_order[\"returned_flag\"] = (ret_order[\"productos_devueltos\"] > 0).astype(int)\n",
    "\n",
    "# ============================================================\n",
    "# 3) Build transactional df\n",
    "# ============================================================\n",
    "df = sales.merge(\n",
    "    product[[COL[\"product_id\"], COL[\"category\"], COL[\"subcat\"]]],\n",
    "    on=COL[\"product_id\"], how=\"left\"\n",
    ")\n",
    "\n",
    "df = df.merge(customer, on=COL[\"customer_id\"], how=\"left\")\n",
    "df = df.merge(rm, on=COL[\"region\"], how=\"left\")\n",
    "df = df.merge(ret_order[[COL[\"order_id\"], \"returned_flag\", \"productos_devueltos\"]],\n",
    "              on=COL[\"order_id\"], how=\"left\")\n",
    "\n",
    "df[\"returned_flag\"] = df[\"returned_flag\"].fillna(0).astype(int)\n",
    "df[\"productos_devueltos\"] = df[\"productos_devueltos\"].fillna(0)\n",
    "\n",
    "# Guarantee after merge\n",
    "if COL[\"category\"] not in df.columns:\n",
    "    df[COL[\"category\"]] = np.nan\n",
    "if COL[\"subcat\"] not in df.columns:\n",
    "    df[COL[\"subcat\"]] = np.nan\n",
    "\n",
    "# ============================================================\n",
    "# 4) Order-level dataset (1 fila por Order_ID)\n",
    "# ============================================================\n",
    "order_tbl = (df.groupby([COL[\"order_id\"], COL[\"customer_id\"]], as_index=False)\n",
    "             .agg(\n",
    "                 order_date=(COL[\"order_date\"], \"min\"),\n",
    "                 order_sales=(COL[\"sales\"], \"sum\"),\n",
    "                 order_profit=(COL[\"profit\"], \"sum\"),\n",
    "                 order_qty=(COL[\"qty\"], \"sum\"),\n",
    "                 discount_mean=(\"Discount_clean\", \"mean\"),\n",
    "                 discount_max=(\"Discount_clean\", \"max\"),\n",
    "                 n_lines=(COL[\"product_id\"], \"count\"),\n",
    "                 n_products=(COL[\"product_id\"], \"nunique\"),\n",
    "                 cat_div=(COL[\"category\"], \"nunique\"),\n",
    "                 subcat_div=(COL[\"subcat\"], \"nunique\"),\n",
    "                 ship_mode=(COL[\"ship_mode\"], mode_or_first),\n",
    "                 region=(COL[\"region\"], mode_or_first),\n",
    "                 country=(COL[\"country\"], mode_or_first),\n",
    "                 returned_flag=(\"returned_flag\", \"max\")\n",
    "             ))\n",
    "\n",
    "# Time features\n",
    "order_tbl[\"order_month\"] = order_tbl[\"order_date\"].dt.month\n",
    "order_tbl[\"order_dow\"] = order_tbl[\"order_date\"].dt.dayofweek\n",
    "order_tbl[\"is_weekend\"] = (order_tbl[\"order_dow\"] >= 5).astype(int)\n",
    "\n",
    "# ============================================================\n",
    "# 5) Customer historical features (SIN leakage)\n",
    "# ============================================================\n",
    "order_tbl = order_tbl.sort_values([COL[\"customer_id\"], \"order_date\"]).reset_index(drop=True)\n",
    "g = order_tbl.groupby(COL[\"customer_id\"], group_keys=False)\n",
    "\n",
    "order_tbl[\"prior_orders\"] = g.cumcount()\n",
    "order_tbl[\"prior_returns\"] = g[\"returned_flag\"].apply(lambda s: s.shift().fillna(0).cumsum())\n",
    "\n",
    "order_tbl[\"prior_return_rate\"] = np.where(\n",
    "    order_tbl[\"prior_orders\"] > 0,\n",
    "    order_tbl[\"prior_returns\"] / order_tbl[\"prior_orders\"],\n",
    "    0.0\n",
    ")\n",
    "\n",
    "order_tbl[\"prior_avg_discount\"] = g[\"discount_mean\"].apply(lambda s: s.shift().expanding().mean()).fillna(0.0)\n",
    "order_tbl[\"prior_avg_order_sales\"] = g[\"order_sales\"].apply(lambda s: s.shift().expanding().mean())\n",
    "order_tbl[\"prior_avg_order_sales\"] = order_tbl[\"prior_avg_order_sales\"].fillna(order_tbl[\"order_sales\"].median())\n",
    "\n",
    "order_tbl[\"prev_order_date\"] = g[\"order_date\"].shift(1)\n",
    "order_tbl[\"recency_at_order_days\"] = (order_tbl[\"order_date\"] - order_tbl[\"prev_order_date\"]).dt.days\n",
    "order_tbl[\"recency_at_order_days\"] = order_tbl[\"recency_at_order_days\"].fillna(order_tbl[\"recency_at_order_days\"].median())\n",
    "order_tbl.drop(columns=[\"prev_order_date\"], inplace=True)\n",
    "\n",
    "# ============================================================\n",
    "# 6) Add customer demographics (y forzar numérico donde aplique)\n",
    "# ============================================================\n",
    "demo_cols = [\n",
    "    \"monthly_salary\",\n",
    "    \"age\",\n",
    "    \"marital_status [1:married/ 0:Single]\",\n",
    "    \"credit score\"\n",
    "]\n",
    "keep_demo = [COL[\"customer_id\"]] + [c for c in demo_cols if c in customer.columns]\n",
    "order_tbl = order_tbl.merge(customer[keep_demo], on=COL[\"customer_id\"], how=\"left\")\n",
    "\n",
    "# >>> FIX adicional: Coerción numérica para demografía (por 'x', 'N/A', etc.)\n",
    "for dc in demo_cols:\n",
    "    if dc in order_tbl.columns:\n",
    "        order_tbl[dc] = pd.to_numeric(order_tbl[dc], errors=\"coerce\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) Train/Test split temporal (holdout)\n",
    "# ============================================================\n",
    "order_tbl = order_tbl.sort_values(\"order_date\").reset_index(drop=True)\n",
    "\n",
    "y = order_tbl[\"returned_flag\"].astype(int)\n",
    "X = order_tbl.drop(columns=[\"returned_flag\"])\n",
    "\n",
    "cutoff = X[\"order_date\"].quantile(0.80)\n",
    "train_idx = X[\"order_date\"] <= cutoff\n",
    "test_idx = X[\"order_date\"] > cutoff\n",
    "\n",
    "X_train = X.loc[train_idx].copy()\n",
    "y_train = y.loc[train_idx].copy()\n",
    "X_test = X.loc[test_idx].copy()\n",
    "y_test = y.loc[test_idx].copy()\n",
    "\n",
    "# Drop raw date\n",
    "X_train = X_train.drop(columns=[\"order_date\"])\n",
    "X_test = X_test.drop(columns=[\"order_date\"])\n",
    "\n",
    "# ============================================================\n",
    "# 8) Preprocess\n",
    "# ============================================================\n",
    "num_features = [\n",
    "    \"order_sales\", \"order_profit\", \"order_qty\",\n",
    "    \"discount_mean\", \"discount_max\",\n",
    "    \"n_lines\", \"n_products\", \"cat_div\", \"subcat_div\",\n",
    "    \"order_month\", \"order_dow\", \"is_weekend\",\n",
    "    \"prior_orders\", \"prior_returns\", \"prior_return_rate\",\n",
    "    \"prior_avg_discount\", \"prior_avg_order_sales\",\n",
    "    \"recency_at_order_days\",\n",
    "] + [c for c in demo_cols if c in X_train.columns]\n",
    "\n",
    "cat_features = [\"ship_mode\", \"region\", \"country\"]\n",
    "\n",
    "# >>> FIX CRÍTICO: forzar numérico en todas las features numéricas ANTES del pipeline\n",
    "for c in num_features:\n",
    "    if c in X_train.columns:\n",
    "        X_train[c] = pd.to_numeric(X_train[c], errors=\"coerce\")\n",
    "    if c in X_test.columns:\n",
    "        X_test[c] = pd.to_numeric(X_test[c], errors=\"coerce\")\n",
    "\n",
    "# (Opcional) Diagnóstico: identificar cuáles columnas traían strings\n",
    "bad_cols = []\n",
    "for c in num_features:\n",
    "    if c in X_train.columns and X_train[c].dtype == \"object\":\n",
    "        s0 = X_train[c]\n",
    "        s1 = pd.to_numeric(s0, errors=\"coerce\")\n",
    "        if s0.notna().sum() > s1.notna().sum():\n",
    "            bad_cols.append(c)\n",
    "if bad_cols:\n",
    "    print(\"Aviso: columnas numéricas tenían strings y fueron convertidas a NaN:\", bad_cols)\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", safe_ohe())\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_features),\n",
    "        (\"cat\", categorical_pipe, cat_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 9) Modelos: baseline + tuning\n",
    "# ============================================================\n",
    "logit = LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"liblinear\")\n",
    "pipe_logit = Pipeline(steps=[(\"prep\", preprocess), (\"model\", logit)])\n",
    "pipe_logit.fit(X_train, y_train)\n",
    "p_logit = pipe_logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "pipe_hgb = Pipeline(steps=[(\"prep\", preprocess), (\"model\", hgb)])\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_dist = {\n",
    "    \"model__learning_rate\": [0.02, 0.05, 0.08, 0.10],\n",
    "    \"model__max_depth\": [3, 5, 7, None],\n",
    "    \"model__max_leaf_nodes\": [15, 31, 63],\n",
    "    \"model__min_samples_leaf\": [20, 50, 100],\n",
    "    \"model__l2_regularization\": [0.0, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipe_hgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=25,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=tscv,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "best_hgb = search.best_estimator_\n",
    "p_hgb = best_hgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ============================================================\n",
    "# 10) Evaluación + umbral top10%\n",
    "# ============================================================\n",
    "def report_metrics(y_true, proba, name=\"model\", threshold=0.5):\n",
    "    pred = (proba >= threshold).astype(int)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"ROC_AUC\": roc_auc_score(y_true, proba),\n",
    "        \"PR_AUC\": average_precision_score(y_true, proba),\n",
    "        \"Precision@thr\": precision_score(y_true, pred, zero_division=0),\n",
    "        \"Recall@thr\": recall_score(y_true, pred, zero_division=0),\n",
    "        \"F1@thr\": f1_score(y_true, pred, zero_division=0),\n",
    "        \"ConfusionMatrix\": confusion_matrix(y_true, pred).tolist()\n",
    "    }\n",
    "\n",
    "def threshold_by_top_pct(proba, top_pct=0.10):\n",
    "    return float(np.quantile(proba, 1 - top_pct))\n",
    "\n",
    "def recall_at_top_pct(y_true, proba, top_pct=0.10):\n",
    "    thr = threshold_by_top_pct(proba, top_pct)\n",
    "    pred = (proba >= thr).astype(int)\n",
    "    return recall_score(y_true, pred, zero_division=0), precision_score(y_true, pred, zero_division=0), thr\n",
    "\n",
    "rec_logit_10, prec_logit_10, thr_logit_10 = recall_at_top_pct(y_test, p_logit, 0.10)\n",
    "rec_hgb_10, prec_hgb_10, thr_hgb_10 = recall_at_top_pct(y_test, p_hgb, 0.10)\n",
    "\n",
    "print(\"\\n=== Baseline Logistic ===\")\n",
    "print(report_metrics(y_test, p_logit, \"Logistic\", threshold=thr_logit_10))\n",
    "print(\"Top10% -> Recall:\", rec_logit_10, \"Precision:\", prec_logit_10, \"Threshold:\", thr_logit_10)\n",
    "\n",
    "print(\"\\n=== Tuned HGB (best) ===\")\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(report_metrics(y_test, p_hgb, \"HGB_tuned\", threshold=thr_hgb_10))\n",
    "print(\"Top10% -> Recall:\", rec_hgb_10, \"Precision:\", prec_hgb_10, \"Threshold:\", thr_hgb_10)\n",
    "\n",
    "print(\"\\nClassification report (HGB_tuned @Top10% threshold):\")\n",
    "print(classification_report(y_test, (p_hgb >= thr_hgb_10).astype(int), zero_division=0))\n",
    "\n",
    "# Lift por deciles (HGB)\n",
    "tmp = pd.DataFrame({\"y\": y_test.values, \"p\": p_hgb})\n",
    "tmp[\"decile\"] = pd.qcut(tmp[\"p\"], 10, labels=False, duplicates=\"drop\")\n",
    "lift = (tmp.groupby(\"decile\")\n",
    "          .agg(n=(\"y\",\"size\"), returns=(\"y\",\"sum\"), return_rate=(\"y\",\"mean\"))\n",
    "          .reset_index()\n",
    "          .sort_values(\"decile\", ascending=False))\n",
    "lift[\"cum_returns\"] = lift[\"returns\"].cumsum()\n",
    "lift[\"cum_return_share\"] = lift[\"cum_returns\"] / lift[\"returns\"].sum()\n",
    "\n",
    "print(\"\\nLift (deciles, HGB):\")\n",
    "print(lift)\n",
    "\n",
    "# ============================================================\n",
    "# 11) Exportables\n",
    "# ============================================================\n",
    "pred_out = X.loc[test_idx, [COL[\"order_id\"], COL[\"customer_id\"], \"order_sales\", \"discount_mean\", \"ship_mode\", \"region\"]].copy()\n",
    "pred_out[\"y_true_returned\"] = y_test.values\n",
    "pred_out[\"p_return_hgb\"] = p_hgb\n",
    "pred_out[\"flag_top10pct\"] = (p_hgb >= thr_hgb_10).astype(int)\n",
    "\n",
    "pred_out.to_csv(\"order_return_predictions.csv\", index=False)\n",
    "lift.to_csv(\"lift_deciles_hgb.csv\", index=False)\n",
    "\n",
    "print(\"\\nGuardados:\")\n",
    "print(\"- order_return_predictions.csv\")\n",
    "print(\"- lift_deciles_hgb.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
